# -*- coding: utf-8 -*-
"""SHROOM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HEoqFG5Rivhh8tGkhXel-awgT0DxNwl0

**IMPORTS**

---
"""

import pandas as pd
import re
import transformers
from transformers import RobertaTokenizer

"""**AGNOSTIC AND MODEL AWARE DATAFRAMES**

---


"""

df_ag = pd.read_json("/content/val.model-agnostic.json")
df_ma = pd.read_json("/content/val.model-aware.v2.json")

df_ag.head()

"""**DATA CLEANING**

---


"""

def clean(text):
    text = text.lower()
    text = re.sub(r"[!\"#\$%&\'\(\)\*\+,-\./:;<=>\?@\[\\\]\^_`{\|}~]" , "" , text)
    text = text.strip()
    return text

df_ag['hyp'] = df_ag['hyp'].apply(clean)
df_ag['src'] = df_ag['src'].apply(clean)
df_ag['tgt'] = df_ag['tgt'].apply(clean)
#hyp src and tgt are filtered to keep pure text and eliminate irrelevant expressions

#only to be executed one time
df_ag.drop("labels", axis=1)
df_ag.drop("label", axis=1)
df_ag.drop("model", axis=1)
#test
df_ag.head()

"""**ADDING LABEL COLUMN**

0 : not hallucinating

1 : hallucinating

---


"""

for index, row in df_ag.iterrows():
  p_int = int(row['p(Hallucination)']) #typecasting into int
  if p_int >= 5:
      #HALLUCINATING = 1
      df_ag.loc[index, 'p(Hallucination)'] = 1
  else:
      #NOT HALLUCINATING = 0
      df_ag.loc[index, 'p(Hallucination)'] = 0

df_ag.head()

"""**USING RoBERTa TOKENIZER**

---


"""

tok = RobertaTokenizer.from_pretrained('roberta-base')

#framework (tensorflow for now)
fw = 'tf'

#input encodings
encodings = []

for index, row in df_ag.iterrows():
    hyp_encoding = tok(row['hyp'], return_tensors = fw, return_token_type_ids=True)
    src_encoding = tok(row['src'], return_tensors = fw, return_token_type_ids=True)
    tgt_encoding = tok(row['tgt'], return_tensors = fw, return_token_type_ids=True)

    encodings.append({"hyp_input_ids" : hyp_encoding["input_ids"],
                      "hyp_attention_mask" : hyp_encoding["attention_mask"],
                      "hyp_token_ids" : hyp_encoding["token_type_ids"],
                      "src_input_ids" : src_encoding["input_ids"],
                      "src_attention_mask" : src_encoding["attention_mask"],
                      "src_token_ids" : src_encoding["token_type_ids"],
                      "tgt_input_ids" : tgt_encoding["input_ids"],
                      "tgt_attention_mask" : tgt_encoding["attention_mask"],
                      "tgt_token_ids" : tgt_encoding["token_type_ids"]})

print(encodings)